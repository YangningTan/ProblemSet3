---
title: "ProblemSet3"
author: "Yangning Tan"
format: html
editor: visual
---

## Problem 2

Load the "sakila" database discussed in class into SQLite.

```{r}
library(DBI)
library(RSQLite)
sakila <- dbConnect(RSQLite :: SQLite(), "/Users/tyn/Downloads/sakila_master.db")
```

a.  Aside from English, what language is most common for films? Answer this with a single SQL query.

    ```{r}
    dbGetQuery(sakila, "SELECT l.name, language_id, COUNT(language_id)
                        FROM film f
                        JOIN language l USING(language_id)
                        WHERE language_id != 1
                        GROUP BY l.name, language_id
                        ORDER BY COUNT(language_id)")
    ```

    As a matter of fact, all films are in English. No other language is used.

b.  What genre of movie is the most common in the data, and how many movies are of this genre?

    **Method 1**: use SQL query or queries to extract the appropriate table(s), then use regular R to answer the question.

    ```{r}
    # extract tables from our database
    table_film <- dbGetQuery(sakila, " SELECT * FROM film")

    table_fcate <-dbGetQuery(sakila, "SELECT * FROM film_category")

    table_cate <- dbGetQuery(sakila, "SELECT * FROM category")
    ```

    ```{r}
    library(dplyr)
    # join the first two tables
    join1 <- inner_join(table_film, table_fcate, by = "film_id")

    # join the table "join1" with the third table
    join_final <- inner_join(join1, table_cate, by = "category_id")
    ```

    ```{r}
    frequency_table <- table(join_final$category_id)
    number_movie <- max(frequency_table)
    max_category_id <- as.integer(names(frequency_table[which.max(frequency_table)]))
    vector <- join_final$name[which(join_final$category_id == max_category_id)]
    print(c(vector[1], number_movie))
    ```

    We can get from this method that sports is the most common genre and there are 74 movies in this genre.

    **Method 2**: use a single SQL query to answer the question.

    ```{r}
    dbGetQuery(sakila, "SELECT category_id, c.name, COUNT(category_id)
                    FROM film f
                    JOIN film_category fc USING (film_id)
                    JOIN category c USING (category_id)
                    GROUP BY category_id, c.name
                    ORDER BY COUNT(category_id) DESC
                    LIMIT 1")
    ```

    With the second method, we can get the same conclusion as with the first method.

c.  Identify which country or countries have exactly 9 customers.

    **Method 1**: use SQL query or queries to extract the appropriate table(s), then use regular R to answer the question.

    ```{r}
    table_connected <-dbGetQuery(sakila, "SELECT *
                                        FROM customer c
                                        JOIN address a USING(address_id)
                                        JOIN city ci USING(city_id)
                                        JOIN country co 
                                          ON co.country_id = ci.country_id
                                        ")


    country_freq <- table(table_connected$country)

    country_9 <- names(country_freq[which(country_freq == 9)])
    country_9
    ```

    The answer is "United Kingdom" with the first method.

    **Method 2**: use a single SQL query to answer the question.

    ```{r}
    dbGetQuery(sakila, " SELECT country, co.country_id
                          FROM customer c
                          JOIN address a USING(address_id)
                          JOIN city ci USING(city_id)
                          JOIN country co ON co.country_id = ci.country_id
                          GROUP BY country, co.country_id
                          HAVING COUNT(customer_id) = 9")
    ```

    The answer is also "United Kingdom" with method 2.

## Problem 3

Download the "US - 500 Records" data and import it into R. 

```{r}
setwd("/Users/tyn/Documents/R/ProblemSet3")
data <- read.csv("us-500.csv", header = TRUE)
```

a.  What proportion of email addresses are hosted at a domain with TLD ".net"?

    ```{r}
    num_row <- nrow(data)
    proportion_net <- sum(grepl("net", data$email)) / num_row
    proportion_net
    ```

    The proportion is $14.6\%$.

b.  What proportion of email addresses have at least one non alphanumeric character in them? 

    ```{r}
    alpnum <-grepl("^[[:alnum:]]+@", data$email)
    nonalpnum_prop <- 1 - sum(alpnum) / num_row
    nonalpnum_prop
    ```

    The proportion is $50.6\%$.

c.  What is the most common area code amongst all phone numbers?

    We first check whether for each person, the area code of "phone 1" and "phone 2" are the same.

    ```{r}
    all.equal(substr(data$phone1, 1, 3), substr(data$phone2, 1, 3))
    ```

    Since the result is "TRUE", we only need to find out the most common area code for "phone 1".

    ```{r}
    area_code <- substr(data$phone1, 1, 3)
    area_code_table <- table(area_code)
    most_common_code <- names(area_code_table[which.max(area_code_table)])
    most_common_code
    ```

    The most common area code is "973".

d.  Produce a histogram of the log of the apartment numbers for all addresses.

    We first extract all apartment number.

    ```{r}
    address <- strsplit(data$address, " ")
    apart <- rep(NA, num_row)

    for (i in 1: num_row){
      apart[i] <- address[[i]][length(address[[i]])]
    }
    apart_num<- apart[grep("#", apart)]

    length <- length(apart_num)
    for (i in 1: length){
      apart_num[i] <- substr(apart_num[i], 2, nchar(apart_num[i]))
    }
    apart_num <- as.numeric(apart_num)
    ```

    Then we produce the histogram.

    ```{r}
    hist(log(apart_num), xlab = "log of apartment number")
    ```

e.  [Benford's law](https://en.wikipedia.org/wiki/Benford's_law) is an observation about the distribution of the leading digit of real numerical data. Examine whether the apartment numbers appear to follow Benford's law. Do you think the apartment numbers would pass as real data?

    We first find the leading number for each element in the vector "apart_num".

    ```{r}
    apart_char <- as.character(apart_num)
    lead_dig <- as.numeric(substr(apart_char, 1, 1))
    ```

    Then we construct a vector to store the expected value for each number in sample size of 500.

    ```{r}
    expected_prob <- c(0.301, 0.176, 0.125, 0.097, 0.079, 0.067, 0.058, 0.051, 0.046)

    observed_value <- as.vector(table(lead_dig))
    ```

    ```{r}
    library(ggplot2)

    benford_plot <- data.frame(
      x = observed_value,
      y = expected_prob
    )

    plot <- ggplot(data = benford_plot, aes(x = x, y = y)) +
      geom_line() +
      labs(title = "Benford's Law", x = "observed value", y = "expected probability") +
      theme_minimal() +
      theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14))

    print(plot)
    ```

    From the plot we obtain, the distribution is different from the Benford's distribution. It does not seem to follow the Benford's Law, so I don't think it would pass as real data.

f.  Repeat your analysis of Benford's law on the *last* digit of the street number.

    We first find the street number of each person.

    ```{r}
    street <- rep(NA, num_row)
    for (i in 1: num_row){
      street[i] <- address[[i]][1]
    }

    last_digit <- rep(NA, num_row)

    for (i in 1: num_row){
      last_digit[i] <- as.numeric(substr(street[i], nchar(street[i]), nchar(street[i])))
    }
    ```

    ```{r}
    count_last <- as.vector(table(last_digit))

    library(ggplot2)

    benford_plot <- data.frame(
      x = count_last,
      y = rep(0.1, 10)
    )

    plot <- ggplot(data = benford_plot, aes(x = x, y = y)) +
      geom_line() +
      labs(title = "street numbers", x = "last digit", y = "expected probability") +
      theme_minimal() +
      theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14))

    print(plot)
    ```
